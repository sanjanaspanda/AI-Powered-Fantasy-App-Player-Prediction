{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shoya\\AppData\\Local\\Temp\\ipykernel_2292\\772256346.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[col] = y[col] / data['Player Experience']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "6/6 [==============================] - 65s 3s/step - loss: 1.0011 - mae: 0.7212 - val_loss: 1.0110 - val_mae: 0.7497\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.9810 - mae: 0.7104 - val_loss: 1.0180 - val_mae: 0.7495\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.9702 - mae: 0.7067 - val_loss: 1.0201 - val_mae: 0.7473\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.9564 - mae: 0.6967 - val_loss: 1.0179 - val_mae: 0.7474\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.9395 - mae: 0.6829 - val_loss: 1.0140 - val_mae: 0.7452\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.9201 - mae: 0.6715 - val_loss: 1.0088 - val_mae: 0.7481\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.8877 - mae: 0.6516 - val_loss: 1.0066 - val_mae: 0.7434\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.8605 - mae: 0.6357 - val_loss: 0.9976 - val_mae: 0.7422\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.8405 - mae: 0.6211 - val_loss: 0.9856 - val_mae: 0.7241\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.8206 - mae: 0.6056 - val_loss: 0.9919 - val_mae: 0.7219\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.7808 - mae: 0.5850 - val_loss: 0.9911 - val_mae: 0.7209\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.7533 - mae: 0.5644 - val_loss: 1.0045 - val_mae: 0.7047\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.7287 - mae: 0.5530 - val_loss: 1.0049 - val_mae: 0.6975\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6959 - mae: 0.5356 - val_loss: 1.0071 - val_mae: 0.6992\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.6720 - mae: 0.5264 - val_loss: 1.0502 - val_mae: 0.6891\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.6214 - mae: 0.5015 - val_loss: 1.0429 - val_mae: 0.6817\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.5920 - mae: 0.4915 - val_loss: 1.0351 - val_mae: 0.6764\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.6102 - mae: 0.5086 - val_loss: 1.0425 - val_mae: 0.6838\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.5365 - mae: 0.4778 - val_loss: 1.1706 - val_mae: 0.7008\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.5373 - mae: 0.4889 - val_loss: 1.0598 - val_mae: 0.6826\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.5107 - mae: 0.4782 - val_loss: 1.0059 - val_mae: 0.6777\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.5417 - mae: 0.5049 - val_loss: 0.9541 - val_mae: 0.6456\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.4534 - mae: 0.4515 - val_loss: 1.1475 - val_mae: 0.7101\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.4628 - mae: 0.4645 - val_loss: 1.0443 - val_mae: 0.6759\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.3925 - mae: 0.4296 - val_loss: 0.9621 - val_mae: 0.6418\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 87ms/step - loss: 0.3811 - mae: 0.4162 - val_loss: 1.0651 - val_mae: 0.6678\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 1s 205ms/step - loss: 0.3672 - mae: 0.4152 - val_loss: 1.1313 - val_mae: 0.7034\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 2s 301ms/step - loss: 0.3364 - mae: 0.3890 - val_loss: 0.9958 - val_mae: 0.6514\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.2872 - mae: 0.3646 - val_loss: 1.0444 - val_mae: 0.6456\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 2s 387ms/step - loss: 0.2855 - mae: 0.3627 - val_loss: 1.0108 - val_mae: 0.6462\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 2s 326ms/step - loss: 0.2379 - mae: 0.3361 - val_loss: 1.0356 - val_mae: 0.6448\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 2s 300ms/step - loss: 0.2186 - mae: 0.3185 - val_loss: 1.0008 - val_mae: 0.6337\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 1s 257ms/step - loss: 0.2109 - mae: 0.3095 - val_loss: 0.9980 - val_mae: 0.6369\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 3s 538ms/step - loss: 0.2584 - mae: 0.3540 - val_loss: 1.1477 - val_mae: 0.6993\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 1s 187ms/step - loss: 0.1787 - mae: 0.2892 - val_loss: 0.9493 - val_mae: 0.6044\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.1983 - mae: 0.2999 - val_loss: 1.0062 - val_mae: 0.6370\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.1617 - mae: 0.2773 - val_loss: 1.0549 - val_mae: 0.6600\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1586 - mae: 0.2720 - val_loss: 1.0909 - val_mae: 0.6656\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1475 - mae: 0.2594 - val_loss: 1.0570 - val_mae: 0.6262\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1327 - mae: 0.2504 - val_loss: 1.0959 - val_mae: 0.6449\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1176 - mae: 0.2325 - val_loss: 1.0499 - val_mae: 0.6329\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1200 - mae: 0.2318 - val_loss: 1.0485 - val_mae: 0.6363\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1282 - mae: 0.2373 - val_loss: 1.1972 - val_mae: 0.6903\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.0887 - mae: 0.1987 - val_loss: 1.2227 - val_mae: 0.6637\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0999 - mae: 0.2148 - val_loss: 1.2184 - val_mae: 0.6793\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0944 - mae: 0.1945 - val_loss: 1.2577 - val_mae: 0.6856\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0859 - mae: 0.1941 - val_loss: 1.3579 - val_mae: 0.6900\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0866 - mae: 0.1888 - val_loss: 1.4376 - val_mae: 0.7166\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0699 - mae: 0.1709 - val_loss: 1.4157 - val_mae: 0.6933\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0743 - mae: 0.1763 - val_loss: 1.4437 - val_mae: 0.7088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_enc.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Input, Concatenate, Reshape\n",
    "import joblib\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Encode categorical columns\n",
    "label_enc = LabelEncoder()\n",
    "data['Player Role'] = label_enc.fit_transform(data['Player Role'])\n",
    "data['Team'] = label_enc.fit_transform(data['Team'])\n",
    "\n",
    "features = ['Batting Average', 'Bowling Average', 'Strike Rate', 'Economy Rate', \n",
    "            'Centuries Scored', 'Half Centuries Scored', 'Ducks Scored', \n",
    "            'Wickets Taken Last Match', 'Runs Scored Last Match', \n",
    "            'Player Age', 'Player Experience', 'Player Role', 'Team']\n",
    "\n",
    "X = data[features]\n",
    "y = data[['Runs Scored', 'Wickets Taken', 'Balls Faced', 'Balls Bowled', \n",
    "          'Overs Bowled', 'Maidens Bowled', 'Runs Conceded']]\n",
    "\n",
    "# Normalize y values\n",
    "for col in y.columns:\n",
    "    y[col] = y[col] / data['Player Experience']\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train model\n",
    "def create_model(input_shape):\n",
    "    input_layer = Input(shape=(input_shape,))\n",
    "    reshaped_input = Reshape((input_shape, 1))(input_layer)\n",
    "    \n",
    "    lstm = LSTM(64, return_sequences=True)(reshaped_input)\n",
    "    lstm = LSTM(32)(lstm)\n",
    "    \n",
    "    gru = GRU(64, return_sequences=True)(reshaped_input)\n",
    "    gru = GRU(32)(gru)\n",
    "    \n",
    "    concat = Concatenate()([lstm, gru])\n",
    "    dense1 = Dense(64, activation='relu')(concat)\n",
    "    dense2 = Dense(32, activation='relu')(dense1)\n",
    "    output = Dense(7)(dense2)  \n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = create_model(X_train.shape[1])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=4, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model and scalers\n",
    "model.save('trained_model.h5')\n",
    "joblib.dump(scaler_X, 'scaler_X.pkl')\n",
    "joblib.dump(scaler_y, 'scaler_y.pkl')\n",
    "joblib.dump(label_enc, 'label_enc.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shoya\\AppData\\Local\\Temp\\ipykernel_21604\\1963835851.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[col] = y[col] / data['Player Experience']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "10/10 [==============================] - 19s 390ms/step - loss: 1.0872 - mae: 0.6643 - val_loss: 0.6288 - val_mae: 0.6540\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 1.0675 - mae: 0.6523 - val_loss: 0.6357 - val_mae: 0.6537\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.0363 - mae: 0.6310 - val_loss: 0.6188 - val_mae: 0.6402\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 1.0080 - mae: 0.6039 - val_loss: 0.6192 - val_mae: 0.6255\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.9728 - mae: 0.5821 - val_loss: 0.5951 - val_mae: 0.6044\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.9490 - mae: 0.5705 - val_loss: 0.5308 - val_mae: 0.5741\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.9224 - mae: 0.5646 - val_loss: 0.4947 - val_mae: 0.5468\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.8885 - mae: 0.5600 - val_loss: 0.4781 - val_mae: 0.5317\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.8727 - mae: 0.5554 - val_loss: 0.4396 - val_mae: 0.5149\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.8300 - mae: 0.5473 - val_loss: 0.4861 - val_mae: 0.5489\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.8116 - mae: 0.5457 - val_loss: 0.4443 - val_mae: 0.5235\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.7799 - mae: 0.5319 - val_loss: 0.4479 - val_mae: 0.5203\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.7596 - mae: 0.5345 - val_loss: 0.4154 - val_mae: 0.5136\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.7059 - mae: 0.5124 - val_loss: 0.4447 - val_mae: 0.5302\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.6924 - mae: 0.5088 - val_loss: 0.4535 - val_mae: 0.5374\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.6683 - mae: 0.5167 - val_loss: 0.4443 - val_mae: 0.5272\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.6100 - mae: 0.4765 - val_loss: 0.4194 - val_mae: 0.5100\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.5666 - mae: 0.4624 - val_loss: 0.4780 - val_mae: 0.5474\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5444 - mae: 0.4655 - val_loss: 0.4263 - val_mae: 0.5153\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5294 - mae: 0.4551 - val_loss: 0.4744 - val_mae: 0.5378\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5060 - mae: 0.4505 - val_loss: 0.4472 - val_mae: 0.5138\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.4781 - mae: 0.4374 - val_loss: 0.3935 - val_mae: 0.4813\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.4067 - mae: 0.3919 - val_loss: 0.4219 - val_mae: 0.4805\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.3859 - mae: 0.3907 - val_loss: 0.3630 - val_mae: 0.4559\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.3611 - mae: 0.3800 - val_loss: 0.3826 - val_mae: 0.4790\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.3298 - mae: 0.3600 - val_loss: 0.3403 - val_mae: 0.4199\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.2979 - mae: 0.3432 - val_loss: 0.3149 - val_mae: 0.4191\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.2708 - mae: 0.3320 - val_loss: 0.3062 - val_mae: 0.4083\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.2540 - mae: 0.3166 - val_loss: 0.3237 - val_mae: 0.4183\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.2341 - mae: 0.3108 - val_loss: 0.3341 - val_mae: 0.4110\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.2278 - mae: 0.3092 - val_loss: 0.3317 - val_mae: 0.4254\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2254 - mae: 0.2980 - val_loss: 0.3277 - val_mae: 0.4153\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2093 - mae: 0.2962 - val_loss: 0.3154 - val_mae: 0.4131\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.1920 - mae: 0.2765 - val_loss: 0.3324 - val_mae: 0.4133\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.1824 - mae: 0.2722 - val_loss: 0.3207 - val_mae: 0.4055\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.1631 - mae: 0.2612 - val_loss: 0.3384 - val_mae: 0.4139\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.1730 - mae: 0.2674 - val_loss: 0.3379 - val_mae: 0.4037\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.1848 - mae: 0.2820 - val_loss: 0.3362 - val_mae: 0.4057\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1622 - mae: 0.2659 - val_loss: 0.3228 - val_mae: 0.4235\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.2357 - mae: 0.2891 - val_loss: 0.8363 - val_mae: 0.5324\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3096 - mae: 0.3277 - val_loss: 0.3493 - val_mae: 0.4402\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.2125 - mae: 0.2781 - val_loss: 0.3472 - val_mae: 0.4241\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.1709 - mae: 0.2625 - val_loss: 0.4310 - val_mae: 0.4839\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.1257 - mae: 0.2325 - val_loss: 0.3516 - val_mae: 0.4135\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.1335 - mae: 0.2307 - val_loss: 0.3747 - val_mae: 0.4476\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.1140 - mae: 0.2255 - val_loss: 0.3732 - val_mae: 0.4453\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0959 - mae: 0.2066 - val_loss: 0.3449 - val_mae: 0.4205\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0886 - mae: 0.1999 - val_loss: 0.3527 - val_mae: 0.4308\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0824 - mae: 0.1917 - val_loss: 0.3506 - val_mae: 0.4176\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0789 - mae: 0.1895 - val_loss: 0.3553 - val_mae: 0.4380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_enc.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Input, Concatenate, Reshape\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Encode categorical data\n",
    "label_enc = LabelEncoder()\n",
    "data['Player Role'] = label_enc.fit_transform(data['Player Role'])\n",
    "data['Team'] = label_enc.fit_transform(data['Team'])\n",
    "\n",
    "# Define features and target variables\n",
    "features = ['Batting Average', 'Bowling Average', 'Strike Rate', 'Economy Rate', \n",
    "            'Centuries Scored', 'Half Centuries Scored', 'Ducks Scored', \n",
    "            'Wickets Taken Last Match', 'Runs Scored Last Match', \n",
    "            'Player Age', 'Player Experience', 'Player Role', 'Team']\n",
    "\n",
    "X = data[features]\n",
    "y = data[['Runs Scored', 'Wickets Taken', 'Balls Faced', 'Balls Bowled', \n",
    "          'Overs Bowled', 'Maidens Bowled', 'Runs Conceded', 'Catch taken', 'Caught & Bowled', 'Stumping/Run Out (direct)', 'Run Out (Thrower/Catcher)']]\n",
    "\n",
    "# Normalize target variables\n",
    "for col in y.columns:\n",
    "    y[col] = y[col] / data['Player Experience']\n",
    "\n",
    "# Standardize features and target variables\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the model\n",
    "def create_model(input_shape):\n",
    "    input_layer = Input(shape=(input_shape,))\n",
    "    \n",
    "    reshaped_input = Reshape((input_shape, 1))(input_layer)\n",
    "    \n",
    "    lstm = LSTM(64, return_sequences=True)(reshaped_input)\n",
    "    lstm = LSTM(32)(lstm)\n",
    "    \n",
    "    gru = GRU(64, return_sequences=True)(reshaped_input)\n",
    "    gru = GRU(32)(gru)\n",
    "    \n",
    "    concat = Concatenate()([lstm, gru])\n",
    "    \n",
    "    dense1 = Dense(64, activation='relu')(concat)\n",
    "    dense2 = Dense(32, activation='relu')(dense1)\n",
    "    \n",
    "    output = Dense(11)(dense2)  \n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "model = create_model(X_train.shape[1])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=4, validation_data=(X_test, y_test))\n",
    "model.save('trained_model.h5')\n",
    "joblib.dump(scaler_X, 'scaler_X.joblib')\n",
    "joblib.dump(scaler_y, 'scaler_y.joblib')\n",
    "joblib.dump(label_enc, 'label_enc.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shoya\\AppData\\Local\\Temp\\ipykernel_17224\\2252535938.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[col] = y[col] / player_stats['Player Experience']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1192\n",
      "0\n",
      "0\n",
      "Epoch 1/50\n",
      "446/446 [==============================] - 18s 12ms/step - loss: 0.7537 - mae: 0.5379 - val_loss: nan - val_mae: nan\n",
      "Epoch 2/50\n",
      "446/446 [==============================] - 3s 6ms/step - loss: 0.3506 - mae: 0.2153 - val_loss: nan - val_mae: nan\n",
      "Epoch 3/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.2747 - mae: 0.1688 - val_loss: nan - val_mae: nan\n",
      "Epoch 4/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.2322 - mae: 0.1388 - val_loss: nan - val_mae: nan\n",
      "Epoch 5/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.2108 - mae: 0.1293 - val_loss: nan - val_mae: nan\n",
      "Epoch 6/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1977 - mae: 0.1252 - val_loss: nan - val_mae: nan\n",
      "Epoch 7/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1887 - mae: 0.1227 - val_loss: nan - val_mae: nan\n",
      "Epoch 8/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1820 - mae: 0.1209 - val_loss: nan - val_mae: nan\n",
      "Epoch 9/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1770 - mae: 0.1185 - val_loss: nan - val_mae: nan\n",
      "Epoch 10/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1727 - mae: 0.1173 - val_loss: nan - val_mae: nan\n",
      "Epoch 11/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1693 - mae: 0.1155 - val_loss: nan - val_mae: nan\n",
      "Epoch 12/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1660 - mae: 0.1121 - val_loss: nan - val_mae: nan\n",
      "Epoch 13/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1633 - mae: 0.1109 - val_loss: nan - val_mae: nan\n",
      "Epoch 14/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1610 - mae: 0.1099 - val_loss: nan - val_mae: nan\n",
      "Epoch 15/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1589 - mae: 0.1092 - val_loss: nan - val_mae: nan\n",
      "Epoch 16/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1572 - mae: 0.1084 - val_loss: nan - val_mae: nan\n",
      "Epoch 17/50\n",
      "446/446 [==============================] - 4s 8ms/step - loss: 0.1553 - mae: 0.1080 - val_loss: nan - val_mae: nan\n",
      "Epoch 18/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1536 - mae: 0.1073 - val_loss: nan - val_mae: nan\n",
      "Epoch 19/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1525 - mae: 0.1063 - val_loss: nan - val_mae: nan\n",
      "Epoch 20/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1513 - mae: 0.1064 - val_loss: nan - val_mae: nan\n",
      "Epoch 21/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1501 - mae: 0.1066 - val_loss: nan - val_mae: nan\n",
      "Epoch 22/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1491 - mae: 0.1057 - val_loss: nan - val_mae: nan\n",
      "Epoch 23/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1479 - mae: 0.1052 - val_loss: nan - val_mae: nan\n",
      "Epoch 24/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1470 - mae: 0.1045 - val_loss: nan - val_mae: nan\n",
      "Epoch 25/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1460 - mae: 0.1040 - val_loss: nan - val_mae: nan\n",
      "Epoch 26/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1451 - mae: 0.1038 - val_loss: nan - val_mae: nan\n",
      "Epoch 27/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1443 - mae: 0.1034 - val_loss: nan - val_mae: nan\n",
      "Epoch 28/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1434 - mae: 0.1033 - val_loss: nan - val_mae: nan\n",
      "Epoch 29/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1430 - mae: 0.1024 - val_loss: nan - val_mae: nan\n",
      "Epoch 30/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1422 - mae: 0.1028 - val_loss: nan - val_mae: nan\n",
      "Epoch 31/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1414 - mae: 0.1022 - val_loss: nan - val_mae: nan\n",
      "Epoch 32/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1411 - mae: 0.1024 - val_loss: nan - val_mae: nan\n",
      "Epoch 33/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1402 - mae: 0.1020 - val_loss: nan - val_mae: nan\n",
      "Epoch 34/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1398 - mae: 0.1019 - val_loss: nan - val_mae: nan\n",
      "Epoch 35/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1392 - mae: 0.1015 - val_loss: nan - val_mae: nan\n",
      "Epoch 36/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1390 - mae: 0.1015 - val_loss: nan - val_mae: nan\n",
      "Epoch 37/50\n",
      "446/446 [==============================] - 3s 8ms/step - loss: 0.1383 - mae: 0.1009 - val_loss: nan - val_mae: nan\n",
      "Epoch 38/50\n",
      "446/446 [==============================] - 4s 8ms/step - loss: 0.1377 - mae: 0.1008 - val_loss: nan - val_mae: nan\n",
      "Epoch 39/50\n",
      "446/446 [==============================] - 3s 6ms/step - loss: 0.1374 - mae: 0.1007 - val_loss: nan - val_mae: nan\n",
      "Epoch 40/50\n",
      "446/446 [==============================] - 3s 6ms/step - loss: 0.1370 - mae: 0.1006 - val_loss: nan - val_mae: nan\n",
      "Epoch 41/50\n",
      "446/446 [==============================] - 3s 6ms/step - loss: 0.1364 - mae: 0.1001 - val_loss: nan - val_mae: nan\n",
      "Epoch 42/50\n",
      "446/446 [==============================] - 3s 6ms/step - loss: 0.1361 - mae: 0.1005 - val_loss: nan - val_mae: nan\n",
      "Epoch 43/50\n",
      "446/446 [==============================] - 3s 6ms/step - loss: 0.1354 - mae: 0.0995 - val_loss: nan - val_mae: nan\n",
      "Epoch 44/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1354 - mae: 0.0988 - val_loss: nan - val_mae: nan\n",
      "Epoch 45/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1347 - mae: 0.0993 - val_loss: nan - val_mae: nan\n",
      "Epoch 46/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1345 - mae: 0.0990 - val_loss: nan - val_mae: nan\n",
      "Epoch 47/50\n",
      "446/446 [==============================] - 3s 7ms/step - loss: 0.1342 - mae: 0.0987 - val_loss: nan - val_mae: nan\n",
      "Epoch 48/50\n",
      "446/446 [==============================] - 4s 8ms/step - loss: 0.1338 - mae: 0.0987 - val_loss: nan - val_mae: nan\n",
      "Epoch 49/50\n",
      "446/446 [==============================] - 4s 8ms/step - loss: 0.1335 - mae: 0.0989 - val_loss: nan - val_mae: nan\n",
      "Epoch 50/50\n",
      "446/446 [==============================] - 3s 8ms/step - loss: 0.1331 - mae: 0.0983 - val_loss: nan - val_mae: nan\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "[[ 0.9433084  -0.59965163 -0.89823    -0.7873746 ]\n",
      " [ 0.18528947 -0.23960485 -0.40633178 -0.50696844]\n",
      " [ 0.8327592  -0.60947573 -0.89952636 -0.7773478 ]\n",
      " [ 0.96917945 -0.59585637 -0.8871594  -0.7829058 ]\n",
      " [ 1.0292917  -0.5996789  -0.8986306  -0.79144573]\n",
      " [-1.110804    1.0852158   1.1364818   0.5346854 ]\n",
      " [ 0.9943293  -0.5767232  -0.90740913 -0.7782223 ]\n",
      " [ 0.96315295 -0.59676737 -0.8924644  -0.78465056]\n",
      " [ 1.0049303  -0.5969004  -0.8907182  -0.78631604]\n",
      " [ 0.81417364 -0.61489224 -0.8939953  -0.7723347 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Input, Concatenate, Reshape\n",
    "import joblib\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "# Load and preprocess the data\n",
    "def load_and_preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.drop('file', axis=1)\n",
    "    # Check for NaNs\n",
    "    if data.isna().sum().sum() > 0:\n",
    "        print(\"Data contains NaN values, filling them with 0.\")\n",
    "        data = data.fillna(0)  # Fill NaN values\n",
    "    return data\n",
    "\n",
    "\n",
    "def aggregate_player_stats(data):\n",
    "    # Batter statistics\n",
    "    batter_stats = data.groupby('batter').agg({\n",
    "        'batter_runs': 'sum',\n",
    "        'total_runs': 'sum',\n",
    "        'wicket': 'sum',\n",
    "        'team': lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown'  # Most frequent team\n",
    "    }).reset_index()\n",
    "    batter_stats.columns = ['Player Name', 'Runs Scored', 'Total Runs', 'Outs', 'Team']\n",
    "    batter_stats['Batting Average'] = batter_stats['Runs Scored'] / np.maximum(batter_stats['Outs'], 1)\n",
    "    \n",
    "    # Bowler statistics\n",
    "    bowler_stats = data.groupby('bowler').agg({\n",
    "        'total_runs': 'sum',\n",
    "        'wicket': 'sum',\n",
    "        'over': 'count',\n",
    "        'team': lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown'  # Most frequent team\n",
    "    }).reset_index()\n",
    "    bowler_stats.columns = ['Player Name', 'Runs Conceded', 'Wickets Taken', 'Balls Bowled', 'Team']\n",
    "    bowler_stats['Bowling Average'] = bowler_stats['Runs Conceded'] / np.maximum(bowler_stats['Wickets Taken'], 1)\n",
    "    bowler_stats['Economy Rate'] = (bowler_stats['Runs Conceded'] / bowler_stats['Balls Bowled']) * 6\n",
    "    \n",
    "    # Merge batter and bowler stats\n",
    "    player_stats = pd.merge(batter_stats, bowler_stats, on=['Player Name', 'Team'], how='outer').fillna(0)\n",
    "    \n",
    "    # Calculate additional features\n",
    "    player_stats['Strike Rate'] = (player_stats['Runs Scored'] / np.maximum(player_stats['Balls Bowled'], 1)) * 100\n",
    "    player_stats['Player Experience'] = player_stats['Balls Bowled'] + player_stats['Total Runs']\n",
    "    \n",
    "    # Add a simple Player Role assignment (you might want to refine this)\n",
    "    player_stats['Player Role'] = player_stats.apply(\n",
    "        lambda row: 'Bowler' if row['Wickets Taken'] > 10 else 'Batsman' if row['Runs Scored'] > 500 else 'All-Rounder',\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return player_stats\n",
    "# Prepare features and target variables\n",
    "def prepare_data(player_stats):\n",
    "    features = ['Batting Average', 'Bowling Average', 'Strike Rate', 'Economy Rate', 'Player Experience']\n",
    "    X = player_stats[features]\n",
    "    y = player_stats[['Runs Scored', 'Wickets Taken', 'Balls Bowled', 'Runs Conceded']]\n",
    "    \n",
    "    # Normalize target variables\n",
    "    for col in y.columns:\n",
    "        y[col] = y[col] / player_stats['Player Experience']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Create the model\n",
    "def create_model(input_shape):\n",
    "    input_layer = Input(shape=(input_shape,))\n",
    "    \n",
    "    reshaped_input = Reshape((1, input_shape))(input_layer)\n",
    "    \n",
    "    lstm = LSTM(64, return_sequences=True, kernel_regularizer=l2(0.001))(reshaped_input)\n",
    "    lstm = LSTM(32, kernel_regularizer=l2(0.001))(lstm)\n",
    "    \n",
    "    gru = GRU(64, return_sequences=True, kernel_regularizer=l2(0.001))(reshaped_input)\n",
    "    gru = GRU(32, kernel_regularizer=l2(0.001))(gru)\n",
    "    \n",
    "    concat = Concatenate()([lstm, gru])\n",
    "    \n",
    "    dense1 = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(concat)\n",
    "    dense2 = Dense(32, activation='relu', kernel_regularizer=l2(0.001))(dense1)\n",
    "    \n",
    "    output = Dense(4)(dense2)  # 4 output variables\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    data = load_and_preprocess_data('../combined_standardized_innings_output_of_all_types.csv')\n",
    "    player_stats = aggregate_player_stats(data)\n",
    "    player_stats.to_csv('aggregated_player_stats.csv', index=False)\n",
    "    # Prepare features and target variables\n",
    "    X, y = prepare_data(player_stats)\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    y_scaled = scaler_y.fit_transform(y)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "    # Check for NaN or infinite values in features and target variables\n",
    "    print(np.isnan(X_train).sum())\n",
    "    print(np.isnan(y_train).sum())\n",
    "    print(np.isinf(X_train).sum())\n",
    "    print(np.isinf(y_train).sum())\n",
    "\n",
    "    # Replace NaNs or Infs with zeros or an appropriate value\n",
    "    X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    y_train = np.nan_to_num(y_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_model(X_train.shape[1])\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "    # Perform a test prediction to check the output range\n",
    "    test_pred = model.predict(X_train[:10])\n",
    "    print(test_pred)\n",
    "\n",
    "    # Save the model and scalers\n",
    "    model.save('trained_model.h5')\n",
    "    joblib.dump(scaler_X, 'scaler_X.joblib')\n",
    "    joblib.dump(scaler_y, 'scaler_y.joblib')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
