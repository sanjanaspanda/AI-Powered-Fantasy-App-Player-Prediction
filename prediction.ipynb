{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shoya\\AppData\\Local\\Temp\\ipykernel_4208\\422006112.py:10: DtypeWarning: Columns (12,13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('ball_by_ball_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m     62\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcricket_score_prediction_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\shoya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assume data is already loaded into a pandas DataFrame\n",
    "df = pd.read_csv('ball_by_ball_data.csv')\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_data(df):\n",
    "    # Label encoding for categorical variables\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['batsman'] = label_encoder.fit_transform(df['batsman'])\n",
    "    df['bowler'] = label_encoder.fit_transform(df['bowler'])\n",
    "    df['batting_team'] = label_encoder.fit_transform(df['batting_team'])\n",
    "    df['bowling_team'] = label_encoder.fit_transform(df['bowling_team'])\n",
    "    \n",
    "    # Normalize the numerical features\n",
    "    scaler = MinMaxScaler()\n",
    "    df[['inning', 'over', 'ball', 'batsman_runs', 'extra_runs', 'total_runs']] = scaler.fit_transform(df[['inning', 'over', 'ball', 'batsman_runs', 'extra_runs', 'total_runs']])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Sequence creation\n",
    "def create_sequences(df, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(df) - sequence_length):\n",
    "        sequence = df.iloc[i:i+sequence_length].values\n",
    "        sequences.append(sequence)\n",
    "    return np.array(sequences)\n",
    "\n",
    "sequence_length = 10  # Choose a sequence length based on your data\n",
    "sequences = create_sequences(df, sequence_length)\n",
    "\n",
    "# Split data into input features (X) and target variable (y)\n",
    "X = sequences[:, :-1, :]\n",
    "y = sequences[:, -1, 6]  # Assuming the target is 'total_runs' for prediction\n",
    "\n",
    "# Reshape X for LSTM/GRU\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(GRU(32, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))  # Regression output for predicting runs\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=20, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Save the model\n",
    "model.save('cricket_score_prediction_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Sample players list\n",
    "players_list = [\n",
    "    {\"Player Name\": \"SC Ganguly\", \"Team\": \"Kolkata Knight Riders\"},\n",
    "    {\"Player Name\": \"BB McCullum\", \"Team\": \"Kolkata Knight Riders\"},\n",
    "    {\"Player Name\": \"RT Ponting\", \"Team\": \"Kolkata Knight Riders\"},\n",
    "    # ... (more players)\n",
    "    {\"Player Name\": \"V Kohli\", \"Team\": \"Royal Challengers Bangalore\"},\n",
    "]\n",
    "\n",
    "# Assuming you have pre-trained encoders and a trained model\n",
    "player_encoder = LabelEncoder()  # Load or train on all player names\n",
    "team_encoder = LabelEncoder()    # Load or train on all team names\n",
    "\n",
    "# Load the trained model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('path_to_your_lstm_gru_model.h5')\n",
    "\n",
    "# Prepare data for prediction\n",
    "player_names = [p['Player Name'] for p in players_list]\n",
    "teams = [p['Team'] for p in players_list]\n",
    "\n",
    "# Encode the player names and teams\n",
    "encoded_players = player_encoder.transform(player_names)\n",
    "encoded_teams = team_encoder.transform(teams)\n",
    "\n",
    "# Combine the encoded features\n",
    "features = np.array([encoded_players, encoded_teams]).T\n",
    "\n",
    "# Pad sequences if needed (assuming input sequences should be of length 5)\n",
    "features_padded = pad_sequences([features], maxlen=5, padding='post', truncating='post')\n",
    "\n",
    "# Make predictions\n",
    "predicted_points = model.predict(features_padded)\n",
    "\n",
    "# Display the predictions\n",
    "for player, points in zip(players_list, predicted_points[0]):\n",
    "    print(f\"Predicted Fantasy Points for {player['Player Name']} ({player['Team']}): {points:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [[3, 0], [4, 1], [4, 3], [3, 4]]\n",
    "l[-1][0]\n",
    "val, idx = l.pop()\n",
    "\n",
    "print(f'Value: {val}, Index: {idx}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
